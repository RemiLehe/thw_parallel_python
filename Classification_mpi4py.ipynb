{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MPI and `mpi4py`\n",
    "\n",
    "### Installation\n",
    "\n",
    "```\n",
    "conda install -c conda-forge mpi4py\n",
    "```\n",
    "(The standard Anaconda channel for mpi4py is [broken](https://github.com/conda/conda/issues/2277). It is necessary to use the [conda-forge](https://conda-forge.github.io/) channel instead.)\n",
    "\n",
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Digit classification with `mpi4py`\n",
    "\n",
    "## On two processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file parallel_script.py\n",
    "\n",
    "from classification import nearest_neighbor_prediction\n",
    "import numpy as np\n",
    "from mpi4py.MPI import COMM_WORLD as communicator\n",
    "\n",
    "# Load data\n",
    "train_images = np.load('./data/train_images.npy')\n",
    "train_labels = np.load('./data/train_labels.npy')\n",
    "test_images = np.load('./data/test_images.npy')\n",
    "\n",
    "# Use only the data that this rank needs\n",
    "N_test = len(test_images)\n",
    "if communicator.rank == 0:\n",
    "    i_start = 0\n",
    "    i_end = N_test/2\n",
    "elif communicator.rank == 1:\n",
    "    i_start = N_test/2\n",
    "    i_end = N_test    \n",
    "small_test_images = test_images[i_start:i_end]\n",
    "\n",
    "# Predict the results and gather it on rank 0\n",
    "small_test_labels = nearest_neighbor_prediction(small_test_images, train_images, train_labels)\n",
    "test_labels_list = communicator.gather( small_test_labels, root=0 )\n",
    "\n",
    "# Rank 0 merges the results and saves them to a file\n",
    "if communicator.rank == 0:\n",
    "    test_labels = np.hstack( test_labels_list )\n",
    "    np.save('./data/test_labels_parallel_%d.npy' %communicator.rank, small_test_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "! mpirun -np 2 python parallel_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On more processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and split the set of test images\n",
    "test_images = np.load('data/test_images.npy')\n",
    "split_arrays = np.array_split( test_images, 4 )\n",
    "\n",
    "# Print the corresponding shape\n",
    "print( 'Shape of the original array:' )\n",
    "print( test_images.shape )\n",
    "print('Shape of the splitted arrays:')\n",
    "for array in split_arrays:\n",
    "    print( array.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%file parallel_script.py\n",
    "\n",
    "from classification import nearest_neighbor_prediction\n",
    "import numpy as np\n",
    "from mpi4py.MPI import COMM_WORLD as communicator\n",
    "\n",
    "# Load data\n",
    "train_images = np.load('./data/train_images.npy')\n",
    "train_labels = np.load('./data/train_labels.npy')\n",
    "test_images = np.load('./data/test_images.npy')\n",
    "\n",
    "# Split the data\n",
    "# Select the array that is relevant for this rank\n",
    "split_arrays = np.array_split( test_images, communicator.size )\n",
    "small_test_images = split_arrays[ communicator.rank ]\n",
    "\n",
    "# Predict the results and gather it on rank 0\n",
    "small_test_labels = nearest_neighbor_prediction(small_test_images, train_images, train_labels)\n",
    "test_labels_list = communicator.gather( small_test_labels, root=0 )\n",
    "\n",
    "# Rank 0 merges the results and saves them to a file\n",
    "if communicator.rank == 0:\n",
    "    test_labels = np.hstack( test_labels_list )\n",
    "    np.save('./data/test_labels_parallel_%d.npy' %communicator.rank, small_test_labels )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "! mpirun -np 4 python parallel_script.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
